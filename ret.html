

          <div class="container" style="max-width: 990px; margin-bottom:30px;">
            <p style="margin-left: -25px;">2022</p>
            <ol>
             
        <li> Junchen Zhu, Lianli Gao, Jingkuan Song, Yuan-Fang Li, Feng Zheng, Xuelong Li, Heng Tao Shen. Label-Guided Generative Adversarial Network for Realistic Image Synthesis. <strong>TPAMI</strong>, 2022. JCR-1.  [<a href="{code_href}">code</a>] </li>


        <li> Ye Liu, Yaya Cheng, Lianli Gao, Xianglong Liu, Qilong Zhang, Jingkuan Song. Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack. <strong>CVPR</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Xinyu Lyu, Lianli Gao, Yuyu Guo, Zhou Zhao, Hao Huang, Heng Tao Shen, Jingkuan Song. Fine-Grained Predicates Learning for Scene Graph Generation. <strong>CVPR</strong> 2022. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Hao Ni, Jingkuan Song, Xiaopeng Luo, Feng Zheng, Wen Li, Heng Tao Shen. Meta Distribution Alignment for Generalizable Person Re-Identification. <strong>CVPR</strong>. CCF A.  [<a href="{code_href}">code</a>] </li>


        <li> Xiaosu Zhu, Jingkuan Song, Lianli Gao, Feng Zheng, Heng Tao Shen. Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression. <strong>CVPR</strong>. CCF A.  [<a href="{code_href}">code</a>] </li>


        <li> Qilong Zhang, Xiaodan Li, Yuefeng Chen, Jingkuan Song, Lianli Gao, Yuan He, Hui Xue. Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains. <strong>ICLR</strong>.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Yu Lei, Pengpeng Zeng, Jingkuan Song, Meng Wang, Heng Tao Shen. Hierarchical Representation Network with Auxiliary Tasks for Video Captioning and Visual question answering. <strong>TIP</strong>. JCR-1.  [<a href="{code_href}">code</a>] </li>


        <li> Pengpeng Zeng, Haonan Zhang, Jingkuan Song, Lianli Gao. S2 Transformer for Image Captioning. <strong>IJCAI</strong>. CCF A.  [<a href="{code_href}">code</a>] </li>


        <li> Xuanhan Wang, Lianli Gao, Yixuan Zhou, Jingkuan Song, Meng Wang. KTN: Knowledge Transfer Network for Learning Multi-person 2D-3D Correspondences. <strong>TCSVT</strong>. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Ji Zhang, Jingkuan Song, Lianli Gao, Ye Liu, Hengtao Shen, Progressive Meta-learning with Curriculum, IEEE Transactions on Circuits and Systems for Video Technology. <strong>TCSVT</strong>. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Jingkuan Song, Jingqiu Zhang, Lianli Gao, Zhou Zhao, Heng Tao Shen. AgeGAN++: Face Aging and Rejuvenation With Dual Conditional GANs.. <strong>TMM</strong>, 2022. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Xiangpeng Li, Bo Wu, Jingkuan Song, Lianli Gao, Pengpeng Zeng, Chuang Gan. Text-Instance Graph: Exploring Relational Semantics for Text-based Visual Question Answering. <strong>Pattern Recognition</strong>. JCR-2.  [<a href="{code_href}">code</a>] </li>

            </ol>
          </div>


          <div class="container" style="max-width: 990px; margin-bottom:30px;">
            <p style="margin-left: -25px;">2021</p>
            <ol>
             
        <li> Yuyu Guo, Lianli Gao, Xuanhan Wang, Yuxuan Hu, Xing Xu, Xu Lu, Heng Tao Shen, Jingkuan Song. From General to Specific: Informative Scene Graph Generation via Balance Adjustment. <strong>ICCV</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Tao He, Lianli Gao, Jingkuan Song, Yuan-Fang Li. Exploiting Scene Graphs for Human-Object Interaction Detection Tao. <strong>ICCV</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Yuyu Guo, Lianli Gao, Jingkuan Song, Peng Wang, Nicu Sebe, Heng Tao Shen, Xuelong Li. Relation Regularized Scene Graph Generation. TOC. JCR-1.  [<a href="{code_href}">code</a>] </li>


        <li> Yan Dai, Xuanhan Wang, Lianli Gao, Jingkuan Song, Heng Tao Shen. Rsgnet: Relation based skeleton graph network for crowded scenes pose estimation. <strong>AAAI</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Yaya Cheng, Qilong Zhang, Xing Xu, Jingkuan Song. Feature Space Targeted Attacks by Statistic Alignment. <strong>IJCAI</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Sitong Su, Jingkuan Song, Lianli Gao, Junchen Zhu. Towards Unsupervised Deformable-Instances Image-to-Image Translation. In <strong>IJCAI</strong>, 2021. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Zijie Huang, Jingkuan Song, Yang yang, Heng Tao Shen. Push & Pull: Transferable Adversarial Examples With Attentive Attack. <strong>TMM</strong>. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Xuanhan Wang, Lianli Gao, Jingkuan Song, Yuyu Guo, Heng Tao Shen. AMANet: Adaptive Multi-Path Aggregation for Learning Human 2D-3D Correspondences. <strong>TMM</strong> 2021. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Xuanhan Wang, Lianli Gao, Yan Dai, Yixuan Zhou, Jingkuan Song. Semantic-aware Transfer with Instance-adaptive Parsing for Crowded Scenes Pose Estimation. <strong>ACM MM</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Sitong Su, Lianli Gao, Junchen Zhu, Jie Shao, Jingkuan Song. Fully Functional Image Manipulation Using Scene Graphs in A Bounding-Box Free Way. In <strong>ACM MM</strong>,2021. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Ji Zhang, Jingkuan Song, Yazhou Yao, Lianli Gao. Curriculum-Based Meta-learning. <strong>ACM MM</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Hao Ni, Jingkuan Song, Xiaosu Zhu, Feng Zheng, Lianli Gao. Camera-Agnostic Person Re-Identification via Adversarial Disentangling Learning. <strong>ACM MM</strong>. CCF A.  [<a href="{code_href}">code</a>] </li>


        <li> Pengpeng Zeng, Lianli Gao, Xinyu Lyu, Shuaiqi Jing, Jingkuan Song. Conceptual and Syntactical Cross-modal Alignment with Cross-level Consistency for Image-Text Matching. <strong>ACM MM</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Xiangpeng Li, Lianli Gao, Lei Zhao, Jingkuan Song. Exploring Contextual-Aware Representation and Linguistic-Diverse Expression for Visual Dialog. <strong>ACM MM</strong>. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Daiyuan Chen, Zhou Zhao, Jie Shao, Heng Tao Shen. Lightweight dynamic conditional GAN with pyramid attention for text-to-image synthesis. <strong>PR</strong>, 2021. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Lei Zhao, Xinyu Lu, Jingkuan Song, Lianli gao. Guess which? Visual Dialog with Attentive Memory Network. <strong>Pattern Recognition</strong> 2021. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Tangming Chen, Xiangpeng Li, Pengpeng Zeng, Lei Zhao, Yuan-Fang Li. Generalized Pyramid Co-Attention with Learnable Aggregation Net for Video Question Answering. <strong>Pattern Recognition</strong>. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Lei Zhao, Haonan Zhang, Xiangpeng Li, Sen Yang, Yuanfeng Song. You Should Know More: Learning External Knowledge for Visual Dialog. <strong>Neurocomputing</strong>. JCR-2.  [<a href="{code_href}">code</a>] </li>

            </ol>
          </div>


          <div class="container" style="max-width: 990px; margin-bottom:30px;">
            <p style="margin-left: -25px;">2020</p>
            <ol>
             
        <li> Lianli Gao, Xiangpeng Li, Jingkuan Song and Heng Tao Shen. Hierarchical LSTMs with Adaptive Attention for Visual Captioning. IEEE Trans. on Pattern Analysis and Machine Intelligence. <strong>TPAMI</strong> 2020. JCR-1.  [<a href="{code_href}">code</a>] </li>


        <li> Liyang Zhang, Shuaicheng Liu, Donghao Liu, Pengpeng Zeng, Xiangpeng Li, Jingkuan Song, Lianli Gao. Rich Visual Knowledge-Based Augmentation Network for Visual Question Answering. <strong>TNNLS</strong> 2020. JCR-1.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Qilong Zhang, Jingkuan Song, Xianglong Liu, Heng Tao Shen. Patch-wise attack for fooling deep neural network. <strong>ECCV</strong>. CCF-B.  [<a href="{code_href}">code</a>] </li>


        <li> Xuanhan Wang, Lianli Gao, Jingkuan Song, Heng Tao Shen. Ktn: Knowledge transfer network for multi-person densepose estimation. <strong>ACM MM</strong>, 2020. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Junchen Zhu, Jingkuan Song, Feng Zheng, Heng Tao Shen. Lab2Pix: Label-Adaptive Generative Adversarial Network for Unsupervised Image Synthesis. In <strong>ACM MM</strong>, 2020. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Yuyu Guo, Jingkuan Song, Lianli Gao, Heng Tao Shen. One-shot Scene Graph Generation. <strong>ACM MM</strong>, 2020. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Tao Li, Jingkuan Song, Zhou Zhao, Heng Tao Shen. Play and rewind: Context-aware video temporal action proposals. <strong>PR</strong>, 2020. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Yiyue Zhang, Fuhao Zou, Jie Shao, Junyu Lai. Unsupervised urban scene segmentation via domain adaptation. <strong>Neurocomputing</strong>, 2020. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Jingkuan Song, Tao He, Lianli Gao, Xing Xu, Alan Hanjalic, Heng Tao Shen. Unified Binary Generative Adversarial Network for Image Retrieval and Compression. <strong>IJCV</strong>. JCR-1.  [<a href="{code_href}">code</a>] </li>

            </ol>
          </div>


          <div class="container" style="max-width: 990px; margin-bottom:30px;">
            <p style="margin-left: -25px;">2019</p>
            <ol>
             
        <li> Lianli Gao, Daiyuan Chen, Jingkuan Song, Xing Xu, Dongxiang Zhang, Heng Tao Shen. Perceptual Pyramid Adversarial Networks for Text-to-Image Synthesis. In <strong>AAAI</strong>, 2019. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Kaixuan Fan, Jingkuan Song, Xianglong Liu, Xing Xu, Heng Tao Shen, Deliberate Residual based Attention Network for Image Captioning, <strong>AAAI</strong> 2019. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Pengpeng Zeng, Jingkuan Song, Yuan-Fang Li, Tao Mei, Heng Tao Shen, Structured Two-stream Attention Network for Video Question Answering, <strong>AAAI</strong>, 2019. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Xiangpeng Li, Lianli Gao, Xianglong Liu, Wenbing Huang, Chuang Gan, Xiangnan He. Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering, <strong>AAAI</strong> 2019. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Xiangpeng Li, Lianli Gao, Xuanhan Wang, Wu Liu, Xing Xu, Jingkuan Song and Heng Tao Shen, Learnable Aggregating Net with Divergent Loss for Video Question Answering, ACM Multimedia 2019. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Liangfu Cao, Jingkuan Song, Jie Shao, Xing Xu. Question-Led Object Attention for Visual Question Answering, <strong>Neurocomputing</strong>, 2019. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Xuanhan Wang, Lianli Gao. Fused GRU with Semantic-Temporal Attention for Video Captioning, <strong>Neurocomputing</strong>, 2019. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Lianli Gao, Xiaosu Zhu, Jingkuan Song, Zhou Zhao, Heng Tao Shen. Beyond product quantization: deep progressive quantization for image retrieval. <strong>IJCAI</strong> 2019. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Jingkuan Song, Xiaosu Zhu, Lianli Gao, Xin-Shun Xu, Wu Liu, Heng Tao Shen. Deep recurrent quantization for generating sequential binary codes. <strong>IJCAI</strong> 2019. CCF-A.  [<a href="{code_href}">code</a>] </li>

            </ol>
          </div>


          <div class="container" style="max-width: 990px; margin-bottom:30px;">
            <p style="margin-left: -25px;">2018</p>
            <ol>
             
        <li> Jingkuan Song, Jingqiu Zhang, Lianli Gao, Xianglong Liu, Heng Tao Shen. Dual Conditional GANs for Face Aging and Rejuvenation.. In <strong>IJCAI</strong>, 2018. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Jingkuan Song, Pengpeng Zeng, Lianli Gao, Xianglong Liu, Heng Tao Shen. Examine before You Answer: Multi-task Learning with Adaptive-attentions for Multiple-choice VQA. <strong>ACM MM</strong>, 2018. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Jingkuan Song, Yuyu Guo, Lianli Gao, Xuelong Li, Alan Hanjalic, Heng Tao Shen. From Deterministic to Generative: Multi-Modal Stochastic RNNs for Video Captioning. <strong>TNNLS</strong>  2018. JCR-1.  [<a href="{code_href}">code</a>] </li>


        <li> Jingkuan Song, Pengpeng Zeng, Lianli Gao, Heng Tao Shen. From Pixels to Objects: Cubic Visual Attention for Visual Question Answering. <strong>IJCAI</strong> 2018. CCF-A.  [<a href="{code_href}">code</a>] </li>

            </ol>
          </div>


          <div class="container" style="max-width: 990px; margin-bottom:30px;">
            <p style="margin-left: -25px;">2017</p>
            <ol>
             
        <li> Lianli Gao, Zhao Guo, Hanwang Zhang, Xing Xu, Heng Tao Shen*. “Videos Captioning with Attention-based LSTM and Semantic Consistency”. IEEE Trans. on Multimedia. JCR-2.  [<a href="{code_href}">code</a>] </li>


        <li> Jingkuan Song, Lianli Gao, Zhao Guo, Wu Liu, Dongxiang Zhang, Heng Tao Shen. "Hierarchical LSTM with Adjusted Temporal Attention for Video Captioning", <strong>IJCAI</strong> 2017. CCF-A.  [<a href="{code_href}">code</a>] </li>


        <li> Jingdong Wang, Ting Zhang, jingkuan song, Nicu Sebe, Heng Tao Shen. A Survey on Learning to Hash. <strong>TPAMI</strong>. JCR-1.  [<a href="{code_href}">code</a>] </li>

            </ol>
          </div>


          <div class="container" style="max-width: 990px; margin-bottom:30px;">
            <p style="margin-left: -25px;">2016</p>
            <ol>
             
        <li> Zhao Guo, Lianli Gao, Jingkuan Song, Xing Xu, Jie Shao, Heng Tao Shen, “Attention-based LSTM with Semantic Consistency for Videos captioning ", <strong>ACM MM</strong> 2016.   CCF-A.  [<a href="{code_href}">code</a>] </li>

            </ol>
          </div>
